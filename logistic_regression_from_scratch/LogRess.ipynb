{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1, x2, x3, y\n",
    "1,  3,  5,  1\n",
    "2,  4,  4,  0\n",
    ".           1 \n",
    ".           1\n",
    "            0\n",
    "            \n",
    "(satır, sütun) => (5, 1) => (5,)\n",
    "               => (1, 5)\n",
    "\n",
    "w = weights\n",
    "b = bias\n",
    "\n",
    "z = w1.x1 + w2.x2 + w3.x3 + b\n",
    "\n",
    "sigmoid = 1 / 1 + exp(-z)\n",
    "\n",
    "y_hat =   1 / 1 + exp(- (w1.x1 + w2.x2 + w3.x3 + b))\n",
    "\n",
    "0, 1\n",
    "\n",
    "y_hat >= 0.5: y_hat = 1\n",
    "y_hat < 0.5: y_hat = 0\n",
    "    \n",
    "X (nx, m)\n",
    "W\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binClass():\n",
    "    \n",
    "    def __init__(self, num_iter=10000, learning_rate=5e-5):\n",
    "        self.num_iters = num_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train = X_train.T.astype(np.float128)\n",
    "        y_train = y_train.values.reshape((1,-1)).astype(np.float128)\n",
    "        \n",
    "        W, b = self.initParams(X_train.shape[0])\n",
    "        costs = []\n",
    "        \n",
    "        for i in range(self.num_iters):\n",
    "            grads, cost = self.prop(X_train, y_train, W, b)\n",
    "            \n",
    "            dW = grads['dW']\n",
    "            db = grads['db']\n",
    "            \n",
    "            W, b = self.update(W, b, dW, db, self.learning_rate)\n",
    "            \n",
    "            if i%1000 == 0:\n",
    "                costs.append(cost)\n",
    "                print(f'{i}th iteration, cost: {cost}')\n",
    "\n",
    "        params = {'W' : W, \n",
    "                  'b' : b}\n",
    "        \n",
    "        grads = {'dW': dW,\n",
    "                 'db': db}\n",
    "        \n",
    "        self.params = params\n",
    "        \n",
    "        return params, grads, cost\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_test = X_test.T.astype(np.float128)\n",
    "        \n",
    "        W = self.params['W']\n",
    "        b = self.params['b']\n",
    "        \n",
    "        A = self.forwProp(X_test, W, b)\n",
    "        preds = np.zeros((1, X_test.shape[1]))\n",
    "        \n",
    "        for i in range(A.shape[1]):\n",
    "            if A[0, i] < 0.5:\n",
    "                preds[0, i] = 0\n",
    "            if A[0 ,i] >= .5:\n",
    "                preds[0, i] = 1\n",
    "        \n",
    "        preds = np.squeeze(preds)\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "    def initParams(self, dim):\n",
    "        W = np.zeros((dim, 1))\n",
    "        b = 0\n",
    "        \n",
    "        return W, b\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        Z = 1 / (1 + np.exp(-Z))\n",
    "        \n",
    "        return (Z)\n",
    "    \n",
    "    def forwProp(self, X_train, W, b):\n",
    "        A = self.sigmoid(np.dot(W.T, X_train) + b)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def calcCost(self, m, Y, A):\n",
    "        loss = -(np.sum(np.multiply(Y, np.log(A)) + np.multiply((1-Y), np.log(1-A)))) / m\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def calcGrads(self, m, X_train, y_train, A):\n",
    "        dW = np.dot(X_train, (A-y_train).T) / m\n",
    "        db = np.sum(A-y_train) / m\n",
    "        \n",
    "        return dW, db\n",
    "    \n",
    "    def update(self, W, b, dW, db, learning_rate):\n",
    "        W = W - (learning_rate * dW)\n",
    "        b = b - (learning_rate * db)\n",
    "        \n",
    "        return W, b\n",
    "    \n",
    "    def prop(self, X_train, y_train, W, b):\n",
    "        \n",
    "        A = self.forwProp(X_train, W, b)\n",
    "        \n",
    "        cost = self.calcCost(X_train.shape[0], y_train, A)\n",
    "        dW, db = self.calcGrads(X_train.shape[0], X_train, y_train, A)\n",
    "        \n",
    "        grad = {'dW' : dW,\n",
    "                'db' : db}\n",
    "        \n",
    "        return grad, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/BinaryClassification/nba_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Name', 'TARGET_5Yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['TARGET_5Yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = binClass(num_iter=50000, learning_rate=8e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration, cost: 38.779760680801154\n",
      "1000th iteration, cost: 38.09237786441654\n",
      "2000th iteration, cost: 37.52520281902547\n",
      "3000th iteration, cost: 37.05448798910944\n",
      "4000th iteration, cost: 36.661052244437535\n",
      "5000th iteration, cost: 36.32961452101732\n",
      "6000th iteration, cost: 36.04808531539453\n",
      "7000th iteration, cost: 35.80692147635303\n",
      "8000th iteration, cost: 35.59858295910153\n",
      "9000th iteration, cost: 35.41709482001784\n",
      "10000th iteration, cost: 35.25770250832443\n",
      "11000th iteration, cost: 35.11660405673352\n",
      "12000th iteration, cost: 34.99074324169423\n",
      "13000th iteration, cost: 34.877650072913724\n",
      "14000th iteration, cost: 34.7753176231096\n",
      "15000th iteration, cost: 34.68210662761318\n",
      "16000th iteration, cost: 34.59667128580959\n",
      "17000th iteration, cost: 34.517901275499334\n",
      "18000th iteration, cost: 34.44487620441395\n",
      "19000th iteration, cost: 34.376829642094435\n",
      "20000th iteration, cost: 34.313120566636385\n",
      "21000th iteration, cost: 34.25321057949398\n",
      "22000th iteration, cost: 34.19664563080986\n",
      "23000th iteration, cost: 34.143041290500555\n",
      "24000th iteration, cost: 34.09207082123201\n",
      "25000th iteration, cost: 34.04345547678603\n",
      "26000th iteration, cost: 33.996956576702964\n",
      "27000th iteration, cost: 33.95236900551327\n",
      "28000th iteration, cost: 33.9095158597616\n",
      "29000th iteration, cost: 33.86824402388765\n",
      "30000th iteration, cost: 33.828420500958586\n",
      "31000th iteration, cost: 33.78992935931328\n",
      "32000th iteration, cost: 33.75266918367896\n",
      "33000th iteration, cost: 33.71655094099305\n",
      "34000th iteration, cost: 33.681496188320494\n",
      "35000th iteration, cost: 33.64743556390297\n",
      "36000th iteration, cost: 33.61430751327591\n",
      "37000th iteration, cost: 33.5820572111326\n",
      "38000th iteration, cost: 33.55063564665578\n",
      "39000th iteration, cost: 33.519998845730605\n",
      "40000th iteration, cost: 33.49010720807294\n",
      "41000th iteration, cost: 33.46092494106965\n",
      "42000th iteration, cost: 33.43241957520283\n",
      "43000th iteration, cost: 33.404561548451355\n",
      "44000th iteration, cost: 33.37732384913668\n",
      "45000th iteration, cost: 33.35068170839102\n",
      "46000th iteration, cost: 33.32461233484117\n",
      "47000th iteration, cost: 33.29909468527585\n",
      "48000th iteration, cost: 33.27410926604098\n",
      "49000th iteration, cost: 33.24963796072209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'W': array([[ 0.19155875],\n",
       "         [ 0.06595626],\n",
       "         [ 0.061133  ],\n",
       "         [ 0.06163178],\n",
       "         [ 0.04689715],\n",
       "         [ 0.10285095],\n",
       "         [-0.00436145],\n",
       "         [-0.02263216],\n",
       "         [ 0.01288685],\n",
       "         [ 0.0630026 ],\n",
       "         [ 0.06105033],\n",
       "         [ 0.0327532 ],\n",
       "         [ 0.09034046],\n",
       "         [ 0.06695696],\n",
       "         [ 0.07880795],\n",
       "         [ 0.04125034],\n",
       "         [ 0.04326419],\n",
       "         [ 0.0849278 ],\n",
       "         [ 0.04512611]], dtype=float128),\n",
       "  'b': 0.20663071425139053706},\n",
       " {'dW': array([[-2.91751568],\n",
       "         [ 0.06880879],\n",
       "         [ 0.07890603],\n",
       "         [ 0.09638381],\n",
       "         [ 0.3061735 ],\n",
       "         [-1.29163157],\n",
       "         [ 0.13761844],\n",
       "         [ 0.56388696],\n",
       "         [-0.48379983],\n",
       "         [-0.05506746],\n",
       "         [ 0.02598092],\n",
       "         [-0.49545442],\n",
       "         [-0.65863811],\n",
       "         [-0.0065204 ],\n",
       "         [-0.26290251],\n",
       "         [-0.23380107],\n",
       "         [ 0.11481016],\n",
       "         [-0.89621104],\n",
       "         [ 0.29426087]], dtype=float128),\n",
       "  'db': -4.133887482392924194},\n",
       " 33.225687611411693995)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7255639097744361"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71,  21],\n",
       "       [ 52, 122]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sk = LogisticRegression(max_iter=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sk = clf_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518796992481203"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  33],\n",
       "       [ 33, 141]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
